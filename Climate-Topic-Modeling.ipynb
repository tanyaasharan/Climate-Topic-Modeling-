{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lEl4mNdkALAT",
        "outputId": "4b075108-7fd7-43c9-c80b-e3502ff0147e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.24.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"climatebert/climate_sentiment\", split=\"train\")"
      ],
      "metadata": {
        "id": "BHXivb3QAarC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df881af0-b39a-4bad-978e-e4ae8c12529f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:3]  # Display first 3 samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meqh9yYrPrBI",
        "outputId": "99ed2e9a-42d2-4134-b9f0-4fe02553a11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['âˆ’ Scope 3: Optional scope that includes indirect emissions associated with the goods and services supply chain produced outside the organization. Included are emissions from the transport of products from our logistics centres to stores (downstream) performed by external logistics operators (air, land and sea transport) as well as the emissions associated with electricity consumption in franchise stores.',\n",
              "  'The Group is not aware of any noise pollution that could negatively impact the environment, nor is it aware of any impact on biodiversity. With regards to land use, the Group is only a commercial user, and the Group is not aware of any local constraints with regards to water supply. The Group does not believe that it is at risk with regards to climate change in the near-or mid-term.',\n",
              "  'Global climate change could exacerbate certain of the threats facing our business, including the frequency and severity of weather-related events referred to in Performance of critical infrastructure in this section 9. In addition, increases in energy prices are partly influenced by government policies to address climate change which, combined with a growing data demand that increases our energy requirements, could increase our energy costs beyond our current expectations.'],\n",
              " 'label': [1, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "cbuNpf6ZP4gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "uTLJ4UcQP5t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting only risk-labeled texts. Label 0\n",
        "risk_texts = [clean(x['text']) for x in dataset if x['label'] == 0]"
      ],
      "metadata": {
        "id": "Uj6_yQcCP8Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "risk_texts[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1E57N4bApOX",
        "outputId": "2826d927-74e6-40d2-a548-28d57e85ddc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the group is not aware of any noise pollution that could negatively impact the environment nor is it aware of any impact on biodiversity with regards to land use the group is only a commercial user and the group is not aware of any local constraints with regards to water supply the group does not believe that it is at risk with regards to climate change in the nearor midterm',\n",
              " 'global climate change could exacerbate certain of the threats facing our business including the frequency and severity of weatherrelated events referred to in performance of critical infrastructure in this section  in addition increases in energy prices are partly influenced by government policies to address climate change which combined with a growing data demand that increases our energy requirements could increase our energy costs beyond our current expectations',\n",
              " 'setting an investment horizon is part and parcel of our policy of focusing on the long term and helping clients to build capital both financial and nonfinancial aspects play a role in measuring investment returns even if we make a successful investment in a mining company today the same company may nonetheless cause damage to the environment tomorrow and thus be compelled to make substantial provisions for improving its wasteprocessing activities and paying fines as an asset manager that focuses on the longterm prospects we cant ignore the nonfinancial aspects']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For vectorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# For topic modeling\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "QX1xrhiHV53l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lda_model(docs, vectorizer_type='count', n_topics=5, max_df=0.95, min_df=2, random_state=42):\n",
        "    if vectorizer_type == 'count':\n",
        "        vectorizer = CountVectorizer(max_df=max_df, min_df=min_df, stop_words='english')\n",
        "    elif vectorizer_type == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df, stop_words='english')\n",
        "    else:\n",
        "        raise ValueError(\"Choose either 'count' or 'tfidf' for vectorizer_type.\")\n",
        "\n",
        "    X = vectorizer.fit_transform(docs)\n",
        "    lda_model = LatentDirichletAllocation(n_components=n_topics, max_iter=10, random_state=random_state)\n",
        "    lda_model.fit(X)\n",
        "\n",
        "    return lda_model, vectorizer, X\n",
        "\n",
        "lda_model_count, vectorizer_count, X_count = train_lda_model(risk_texts, vectorizer_type='count')\n",
        "lda_model_tfidf, vectorizer_tfidf, X_tfidf = train_lda_model(risk_texts, vectorizer_type='tfidf')"
      ],
      "metadata": {
        "id": "q4BsMZdaF_x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display topics, for comparison\n",
        "def compare_topics(lda_model_1, vect_1, lda_model_2, vect_2, label=\"Risk\", n_words=10):\n",
        "    print(f\"{label} Class Topics Comparison\")\n",
        "    for idx in range(lda_model_1.n_components):\n",
        "        topic1_words = [vect_1.get_feature_names_out()[i] for i in lda_model_1.components_[idx].argsort()[:-n_words-1:-1]]\n",
        "        topic2_words = [vect_2.get_feature_names_out()[i] for i in lda_model_2.components_[idx].argsort()[:-n_words-1:-1]]\n",
        "\n",
        "        print(f\"Topic {idx+1}:\")\n",
        "        print(f\"  CountVectorizer : {', '.join(topic1_words)}\")\n",
        "        print(f\"  TFIDFVectorizer : {', '.join(topic2_words)}\\n\")"
      ],
      "metadata": {
        "id": "vBZynaJMPBiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_topics(\n",
        "    lda_model_1=lda_model_count, vect_1=vectorizer_count,\n",
        "    lda_model_2=lda_model_tfidf, vect_2=vectorizer_tfidf,\n",
        "    label=\"Risk\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFFytesfGFFi",
        "outputId": "c66f0477-a255-4add-8efa-bd6dcc3f71fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risk Class Topics Comparison\n",
            "Topic 1:\n",
            "  CountVectorizer : risk, risks, management, climate, climaterelated, impact, including, portfolio, group, scenario\n",
            "  TFIDFVectorizer : risk, risks, climate, change, impact, including, management, energy, increase, impacts\n",
            "\n",
            "Topic 2:\n",
            "  CountVectorizer : climate, change, risk, risks, environmental, projects, business, increased, coal, impact\n",
            "  TFIDFVectorizer : climate, risk, change, risks, carbon, coal, new, emissions, impact, assets\n",
            "\n",
            "Topic 3:\n",
            "  CountVectorizer : climate, change, impact, weather, events, risks, physical, extreme, changes, increase\n",
            "  TFIDFVectorizer : change, risk, climate, impact, risks, physical, increased, production, weather, costs\n",
            "\n",
            "Topic 4:\n",
            "  CountVectorizer : climate, change, carbon, risks, energy, risk, emissions, transition, gas, physical\n",
            "  TFIDFVectorizer : climate, risks, change, risk, carbon, physical, transition, potential, impacts, energy\n",
            "\n",
            "Topic 5:\n",
            "  CountVectorizer : risks, risk, clients, transition, physical, climate, financial, losses, business, impact\n",
            "  TFIDFVectorizer : risks, risk, climate, management, physical, change, companies, financial, business, impact\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.24.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFjdc50hgLZn",
        "outputId": "e38040a8-620a-4d58-e711-6f90c4b05822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "def get_topics_words(lda_model, vectorizer, n_words=10):\n",
        "    terms = vectorizer.get_feature_names_out()\n",
        "    return [[terms[i] for i in topic.argsort()[:-n_words-1:-1]] for topic in lda_model.components_]\n",
        "\n",
        "# Extract top words from both models\n",
        "lda_topics_count = get_topics_words(lda_model_count, vectorizer_count)\n",
        "lda_topics_tfidf = get_topics_words(lda_model_tfidf, vectorizer_tfidf)"
      ],
      "metadata": {
        "id": "8WGvaYQaVBMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_coherence(topics, texts):\n",
        "    tokenized_texts = [t.split() for t in texts]\n",
        "    dictionary = Dictionary(tokenized_texts)\n",
        "    cm = CoherenceModel(topics=topics, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
        "    return cm.get_coherence()\n",
        "\n",
        "# Compute Coherence Scores\n",
        "coherence_count = compute_coherence(lda_topics_count, risk_texts)\n",
        "coherence_tfidf = compute_coherence(lda_topics_tfidf, risk_texts)\n",
        "\n",
        "print(f\"Coherence Score (CountVectorizer): {coherence_count:.4f}\")\n",
        "print(f\"Coherence Score (TFIDFVectorizer): {coherence_tfidf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avhIkvGiWEau",
        "outputId": "5daf417b-2de2-40ef-fbc0-a0aad3a88f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Score (CountVectorizer): 0.4533\n",
            "Coherence Score (TFIDFVectorizer): 0.4083\n"
          ]
        }
      ]
    }
  ]
}